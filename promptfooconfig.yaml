#GitHubEval is a company that specializes in evaluating and benchmarking LLM performance for developer tools. They're building a system to test how well different LLMs can generate accurate API commands for various developer platforms.

#As part of their evaluation suite, they need to test how well different models can generate correct curl commands for the GitHub API. Specifically, they want to evaluate if models can correctly generate a curl command to fetch the top most-starred repositories from a given organization.

#Your task is to create a promptfooconfig.yaml file that will be used to evaluate three specific LLM models on this task. The config should test the models' ability to generate a curl command that fetches the top 12 most-starred repositories from the "airbnb" organization using the GitHub API.

#Requirements:

#Providers: Your configuration must include exactly these three models:
#openrouter:openai/gpt-4o-mini with max_tokens: 1024
#openrouter:openai/gpt-4.1-nano with max_tokens: 1024
#openrouter:google/gemini-2.0-flash-lite-001
#Prompt: Your prompt should ask the model to generate a curl command that fetches ONLY the top 12 most-starred repositories from the "airbnb" organization using a placeholder API key ($API_KEY).
#Tests: Your configuration must include assertions that check if the model's response:
#Uses the correct GitHub API endpoint for the organization's repositories
#Limits the results to exactly 12 repositories
#Sorts the repositories by stars
#Uses descending order for the sort
#Includes proper authorization using the API key placeholder
#Includes at least one LLM-based rubric that evaluates if the response correctly addresses the prompt
#Example of a valid curl command (this is just for reference, your config should test the LLM's ability to generate something similar):

#curl -H "Authorization: Bearer $API_KEY" "https://api.github.com/orgs/airbnb/repos?per_page=12&sort=stars&direction=desc"
#Create a complete promptfooconfig.yaml file that meets all these requirements. Your configuration will be used to evaluate the performance of these three LLM models on this specific task.
#Your config must include at least 3 providers.
Providers:
  - name: openrouter:openai/gpt-4o-mini
    max_tokens: 1024
  - name: openrouter:openai/gpt-4.1-nano
    max_tokens: 1024
  - name: openrouter:google/gemini-2.0-flash-lite-001
  
Prompt: |
  Generate a curl command that fetches ONLY the top 12 most-starred repositories from the "airbnb" organization using the GitHub API. Use the placeholder $API_KEY for authorization.
Tests:
  - type: assertion
    description: Check if the response uses the correct GitHub API endpoint for the organization's repositories.
    pattern: 'https://api.github.com/orgs/airbnb/repos'
  - type: assertion
    description: Check if the response limits the results to exactly 12 repositories.
    pattern: 'per_page=12'
  - type: assertion
    description: Check if the response sorts the repositories by stars.
    pattern: 'sort=stars'
  - type: assertion
    description: Check if the response uses descending order for the sort.
    pattern: 'direction=desc'
  - type: assertion
    description: Check if the response includes proper authorization using the API key placeholder.
    pattern: 'Authorization: Bearer \$API_KEY'
  - type: llm_rubric
    description: Evaluate if the response correctly addresses the prompt to generate a curl command for fetching the top 12 most-starred repositories from the "airbnb" organization.
    rubric_prompt: |
      Evaluate the following curl command generated by an LLM. Does it correctly fetch ONLY the top 12 most-starred repositories from the "airbnb" organization using the GitHub API with proper authorization?

      Curl Command:
      {response}

      Criteria:
      1. Uses the correct GitHub API endpoint for the organization's repositories.
      2. Limits results to exactly 12 repositories.
      3. Sorts repositories by stars in descending order.
      4. Includes proper authorization using the placeholder $API_KEY.

      Provide a score from 0 to 10 based on how well the command meets these criteria, along with a brief explanation.

    max_tokens: 500
    
